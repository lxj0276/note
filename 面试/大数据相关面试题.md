## 大数据相关面试题

### 1. 简要介绍Hadoop中的map-reduce编程模型

​	首先map task会从本地文件系统读取数据，转换成key-value形式的键值对集合，使用的是hadoop内置的数据类型，比如longwritable、text等；将键值对集合输入mapper进行业务处理过程，将其转换成需要的key-value再输出，之后会进行一个partition分区操作，默认使用的是hashpartitioner，可以通过重写hashpartitioner的getpartition方法来自定义分区规则；之后会对key进行sort排序，grouping分组操作将相同key的value合并分组输出，在这里可以使用自定义的数据类型，重写WritableComparator的comparator方法来自定义排序规则，重写RawComparator的comparate方法来自定义分组规则；之后进行一个combiner规约操作，其实就是一个本地段的reduce预处理，以减少后面shuffle和reduce的工作量；reduce task会通过网络将各个数据收集进行reduce处理，最后将数据保存或者显示，结束整个job。

### 2. hadoop的TextInputFormat作用是什么，如何自定义实现

​	InputFormat会在map操作之前对数据进行两方面的预处理：

1. getSplits，返回的是InputSplit数组，对数据进行split分片，每片交给map操作一次；
2. getRecordReader，返回的是RecordReader对象，对每个split分片进行转换为key-value键值对格式传递给map。

常用的InputFormat是TextInputFormat，使用的是LineRecordReader对每个分片进行键值对的转换，以行偏移量作为键，行内容作为值。

自定义类继承InputFormat接口，重写createRecordReader和isSplitable方法，在createRecordReader中可以自定义分隔符。

### 3. **hadoop和spark的都是并行计算，那么他们有什么相同和区别**

​	两者都是用mr模型来进行并行计算，hadoop的一个作业称为job，job里面分为map task和reduce task，每个task都是在自己的进程中运行的，当task结束时，进程也会结束。

​	spark用户提交的任务成为application，一个application对应一个sparkcontext，app中存在多个job，每触发一次action操作就会产生一个job。这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGSchaduler通过RDD之间的依赖关系划分job而来的，每个stage里面有多个task，组成taskset有TaskSchaduler分发到各个executor中执行，executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算。

​	hadoop的job只有map和reduce操作，表达能力比较欠缺而且在mr过程中会重复的读写hdfs，造成大量的io操作，多个job需要自己管理关系。spark的迭代计算都是在内存中进行的，API中提供了大量的RDD操作如join，groupby等，而且通过DAG图可以实现良好的容错。

### 4. **map-reduce程序运行的时候会有什么比较常见的问题**

​	比如说作业中大部分都完成了，但是总有几个reduce一直在运行，这是因为这几个reduce中的处理的数据要远远大于其他的reduce，可能是因为对键值对任务划分的不均匀造成的数据倾斜。解决的方法可以在分区的时候重新定义分区规则对于value数据很多的key可以进行拆分、均匀打散等处理，或者是在map端的combiner中进行数据预处理的操作。

​	其实这就是常说的**数据倾斜**问题，这个在Spark中也会出现，至于解决方式，可以参考我的另一篇笔记。

### 5. Spark中reduce和reduceByKey的区别

1. 最基本的区别是：**reduce**是一个**Action**操作，而**reduceByKey**是一个**transformation**操作，这就可以说到Spark中Action和Transformation这两种操作的区别；
2. 操作的数据集对象有区别，reduceByKey必须是(K,V)键值对的数据集，而reduce并没有限制；
3. reduce完成的功能是对RDD中的元素执行函数指定的聚合操作，也就是针对的RDD中的所有元素而言；而reduceByKey是针对的RDD中具有的相同key的元素的聚合；
4. reduce不会产生shuffle操作事件，而reduceByKey会产生shuffle操作事件。